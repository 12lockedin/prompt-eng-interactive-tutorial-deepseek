{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteratively Searching Wikipedia with DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DISCLAIMER: This notebook was adapted from an original version using Claude models.]\n",
    "\n",
    "Some questions can't be answered by language models off the top of their heads. Maybe they're about current events. Maybe you have an intensely detailed question that the model hasn't memorized the answer to. No worries! With some prompting and scaffolding, the model can search the web to find answers. In this notebook, we will create a virtual research assistant who has the ability to search Wikipedia to find answers to your question. The same approach can be used to allow the model to search the broader web, or a set of documents you provide.\n",
    "\n",
    "What is the approach? Broadly it falls under the category of \"tool use\". We create a search tool, tell the model about it, and let it go to work. In pseudocode:\n",
    "\n",
    "1. Prompt the model with a description of the search tool, how it's best used, and how to \"call\" it (by issuing a special string).\n",
    "2. Tell the model your question.\n",
    "3. The model produces a response. If it produces the special string, terminate the response stream, and issue a query to a search API.\n",
    "4. Construct a new prompt which consists of the prompt from step 1, plus everything the model generated up to the search call string, plus the results of the API call.\n",
    "5. Repeat until the model decides it's done.\n",
    "\n",
    "Let's zoom in on the prompts for tool use and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# Store the API_KEY, BASE_URL & MODEL_NAME variables for use across notebooks within the IPython store\n",
    "%store API_KEY\n",
    "%store BASE_URL\n",
    "%store MODEL_NAME\n",
    "\n",
    "# Initialize the client\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\n"
     ]
    }
   ],
   "source": [
    "# Tool Description Prompt\n",
    "wikipedia_prompt = \"\"\"You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\"\"\"\n",
    "print(wikipedia_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is a lot of advice in this prompt about how to search Wikipedia properly. We're all used to just typing random nonsense into Google and getting decent results because the query parsing logic is so good. Wikipedia search is not like that. As an example: consider the query \"What's the best way to purchase potatoes in the United Arab Emirates\". The [top hits for this on Wikipedia](https://en.wikipedia.org/w/index.php?search=What%27s+the+best+way+to+purchase+potatoes+in+the+United+Arab+Emirates&title=Special:Search&profile=advanced&fulltext=1&ns0=1) are for Slavery in the United States, 1973 Oil Crisis, Wendy's, and Tim Horton's (??). Meanwhile Google correctly takes you straight to Carrefour UAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference is that Wikipedia search returns entire pages. With vector search, you might be getting narrower chunks, so you might want to ask for more results, use a more specific query, or both. The big-picture takeaway is that your results can vary a lot on your choices here so pay attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n"
     ]
    }
   ],
   "source": [
    "retrieval_prompt = \"\"\"Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
    "\n",
    "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
    "\n",
    "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\"\"\"\n",
    "print(retrieval_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use a scratchpad here for the normal chain-of-thought reasons -- it makes the model come up with a coherent plan to answer the question. The search quality reflection is used to induce the model to be persistent and not jump the gun by answering the question before gathering all the relevant information. But why are we telling the model to synthesize the information and not answer right away?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'information' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m answer_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHere is a user query: <query>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</query>. Here is some relevant information: <information>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43minformation\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</information>. Please answer the question using the relevant information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer_prompt)\n",
      "\u001b[31mNameError\u001b[39m: name 'information' is not defined"
     ]
    }
   ],
   "source": [
    "answer_prompt = f\"Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\"\n",
    "print(answer_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By extracting the information and presenting it to the model in a new query, we allow it to focus all its attention on synthesizing the information into the right answer. Without this step, we found that the model would sometimes precommit to an answer and then \"justify\" it with the search results, rather than allowing the results to guide it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now follows a bunch of code that implements the pseudocode for searching + retrieving + reprompting.\n",
    "\n",
    "### Search Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "import wikipedia, re\n",
    "from typing import Tuple, Optional, List, Dict, Any\n",
    "import tiktoken\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"\n",
    "    A single search result.\n",
    "    \"\"\"\n",
    "    content: str\n",
    "\n",
    "class SearchTool:\n",
    "    \"\"\"\n",
    "    A search tool that can run a query and return a formatted string of search results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def raw_search(self, query: str, n_search_results_to_use: int) -> List[SearchResult]:\n",
    "        \"\"\"\n",
    "        Runs a query using the searcher, then returns the raw search results without formatting.\n",
    "\n",
    "        :param query: The query to run.\n",
    "        :param n_search_results_to_use: The number of results to return.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_raw_search_results(\n",
    "        self, results: List[SearchResult],\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extracts the raw search content from the search results and returns a list of strings that can be passed to the model.\n",
    "\n",
    "        :param results: The search results to extract.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def search_results_to_string(self, extracted: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Joins and formats the extracted search results as a string.\n",
    "\n",
    "        :param extracted: The extracted search results to format.\n",
    "        \"\"\"\n",
    "        result = \"\\n\".join(\n",
    "            [\n",
    "                f'<item index=\"{i+1}\">\\n<page_content>\\n{r}\\n</page_content>\\n</item>'\n",
    "                for i, r in enumerate(extracted)\n",
    "            ]\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def wrap_search_results(self, extracted: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Formats the extracted search results as a string, including the <search_results> tags.\n",
    "\n",
    "        :param extracted: The extracted search results to format.\n",
    "        \"\"\"\n",
    "        return f\"\\n<search_results>\\n{self.search_results_to_string(extracted)}\\n</search_results>\"\n",
    "    \n",
    "    def search(self, query: str, n_search_results_to_use: int) -> str:\n",
    "        raw_search_results = self.raw_search(query, n_search_results_to_use)\n",
    "        processed_search_results = self.process_raw_search_results(raw_search_results)\n",
    "        displayable_search_results = self.wrap_search_results(processed_search_results)\n",
    "        return displayable_search_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WikipediaSearchResult(SearchResult):\n",
    "    title: str\n",
    "    \n",
    "class WikipediaSearchTool(SearchTool):\n",
    "\n",
    "    def __init__(self,\n",
    "                 truncate_to_n_tokens: Optional[int] = 5000):\n",
    "        self.truncate_to_n_tokens = truncate_to_n_tokens\n",
    "        if truncate_to_n_tokens is not None:\n",
    "            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Using OpenAI's tokenizer\n",
    "\n",
    "    def raw_search(self, query: str, n_search_results_to_use: int) -> List[WikipediaSearchResult]:\n",
    "        search_results = self._search(query, n_search_results_to_use)\n",
    "        return search_results\n",
    "    \n",
    "    def process_raw_search_results(self, results: List[WikipediaSearchResult]) -> List[str]:\n",
    "        processed_search_results = [f'Page Title: {result.title.strip()}\\nPage Content:\\n{self.truncate_page_content(result.content)}' for result in results]\n",
    "        return processed_search_results\n",
    "\n",
    "    def truncate_page_content(self, page_content: str) -> str:\n",
    "        if self.truncate_to_n_tokens is None:\n",
    "            return page_content.strip()\n",
    "        else:\n",
    "            tokens = self.tokenizer.encode(page_content)\n",
    "            truncated_tokens = tokens[:self.truncate_to_n_tokens]\n",
    "            return self.tokenizer.decode(truncated_tokens).strip()\n",
    "        \n",
    "    def _search(self, query: str, n_search_results_to_use: int) -> List[WikipediaSearchResult]:\n",
    "        results = wikipedia.search(query)\n",
    "        search_results: List[WikipediaSearchResult] = []\n",
    "        for result in results:\n",
    "            if len(search_results) >= n_search_results_to_use:\n",
    "                break\n",
    "            try:\n",
    "                page = wikipedia.page(result)\n",
    "                print(page.url)\n",
    "            except:\n",
    "                # The Wikipedia API is a little flaky, so we just skip over pages that fail to load\n",
    "                continue\n",
    "            content = page.content\n",
    "            title = page.title\n",
    "            search_results.append(WikipediaSearchResult(content=content, title=title))\n",
    "        return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_between_tags(tag: str, string: str, strip: bool = True) -> list[str]:\n",
    "    ext_list = re.findall(f\"<{tag}(?:\\\\s[^>]*)?>(.+?)</{tag}>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list\n",
    "\n",
    "class ClientWithRetrieval:\n",
    "\n",
    "    def __init__(self, search_tool: SearchTool, client: OpenAI, verbose: bool = True):\n",
    "        self.search_tool = search_tool\n",
    "        self.client = client\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count the number of tokens in a text using tiktoken\"\"\"\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        return len(encoding.encode(text))\n",
    "\n",
    "    # Helper methods\n",
    "    def _search_query_stop(self, partial_completion: str, n_search_results_to_use: int) -> Tuple[List[SearchResult], str]:\n",
    "        search_query = extract_between_tags('search_query', partial_completion + '</search_query>') \n",
    "        if not search_query:\n",
    "            raise Exception(f'Completion with retrieval failed as partial completion returned mismatched <search_query> tags.')\n",
    "        print(f'Running search query against SearchTool: {search_query}')\n",
    "        search_results = self.search_tool.raw_search(search_query[0], n_search_results_to_use)\n",
    "        extracted_search_results = self.search_tool.process_raw_search_results(search_results)\n",
    "        formatted_search_results = self.search_tool.wrap_search_results(extracted_search_results)\n",
    "        return search_results, formatted_search_results\n",
    "    \n",
    "    def retrieve(self,\n",
    "                 query: str,\n",
    "                 model: str,\n",
    "                 n_search_results_to_use: int = 3,\n",
    "                 max_tokens_to_sample: int = 1000,\n",
    "                 max_searches_to_try: int = 5,\n",
    "                 temperature: float = 1.0) -> tuple[List[SearchResult], str]:\n",
    "        \n",
    "        system_message = wikipedia_prompt + \" \" + retrieval_prompt.format(query=query)\n",
    "        starting_messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message}\n",
    "        ]\n",
    "        messages = starting_messages.copy()\n",
    "        print(\"Starting system message:\", system_message)\n",
    "        token_budget = max_tokens_to_sample\n",
    "        all_raw_search_results: List[SearchResult] = []\n",
    "        final_model_response = \"\"\n",
    "        \n",
    "        for tries in range(max_searches_to_try):\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_tokens=token_budget,\n",
    "                temperature=temperature,\n",
    "                stop=[\"</search_query>\"]\n",
    "            )\n",
    "            partial_completion = response.choices[0].message.content\n",
    "            print(partial_completion)\n",
    "            token_budget -= self.count_tokens(partial_completion)\n",
    "            final_model_response += partial_completion\n",
    "            messages.append({\"role\": \"assistant\", \"content\": partial_completion})\n",
    "            \n",
    "            if \"<search_query>\" in partial_completion:\n",
    "                print(f'Attempting search number {tries}.')\n",
    "                raw_search_results, formatted_search_results = self._search_query_stop(partial_completion, n_search_results_to_use)\n",
    "                messages.append({\"role\": \"user\", \"content\": \"</search_query>\" + formatted_search_results})\n",
    "                all_raw_search_results += raw_search_results\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return all_raw_search_results, final_model_response\n",
    "    \n",
    "    # Main methods\n",
    "    def completion_with_retrieval(self,\n",
    "                                  query: str,\n",
    "                                  model: str,\n",
    "                                  n_search_results_to_use: int = 3,\n",
    "                                  max_tokens_to_sample: int = 1000,\n",
    "                                  max_searches_to_try: int = 5,\n",
    "                                  temperature: float = 1.0) -> str:\n",
    "        \n",
    "        _, retrieval_response = self.retrieve(query, model=model,\n",
    "                                              n_search_results_to_use=n_search_results_to_use,\n",
    "                                              max_tokens_to_sample=max_tokens_to_sample,\n",
    "                                              max_searches_to_try=max_searches_to_try,\n",
    "                                              temperature=temperature)\n",
    "        \n",
    "        information = extract_between_tags('information', retrieval_response)\n",
    "        if information:\n",
    "            information = information[-1]\n",
    "        else:\n",
    "            information = \"No information found in the search results.\"\n",
    "            \n",
    "        prompt = answer_prompt.format(query=query, information=information)\n",
    "        print(\"Summarizing:\\n\", prompt)\n",
    "        \n",
    "        answer = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=1000\n",
    "        ).choices[0].message.content\n",
    "        \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to execute a query! Let's pick something:\n",
    "- recent, so it's less likely to be in the model's training data, and\n",
    "- compound/complex so it requires multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting system message: You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description> Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>Which is Beyoncé's eigth studio album?</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n",
      "<scratchpad>To answer the user's question, I need to find information about Beyoncé's discography, specifically focusing on her eighth studio album. The most atomic query here would be \"Beyoncé discography\" or \"Beyoncé albums,\" as this will likely provide a comprehensive list of her studio albums, including the eighth one.</scratchpad>\n",
      "\n",
      "<search_query>Beyoncé discography\n",
      "Attempting search number 0.\n",
      "Running search query against SearchTool: ['Beyoncé discography']\n",
      "https://en.wikipedia.org/wiki/Beyonc%C3%A9_albums_discography\n",
      "<search_quality>The search results provide a comprehensive overview of Beyoncé's discography, including detailed information about her studio albums. The eighth studio album, \"Cowboy Carter,\" is explicitly mentioned, along with its release date, chart performance, and accolades. This information is sufficient to answer the user's question.</search_quality>\n",
      "\n",
      "<information>Beyoncé's eighth studio album is \"Cowboy Carter,\" which was released in March 2024. It debuted at number one in several countries, including the United States, and broke several chart and streaming records. The album earned eleven nominations at the 67th Annual Grammy Awards, winning Album of the Year and Best Country Album.</information>\n",
      "Summarizing:\n",
      " Here is a user query: <query>Which is Beyoncé's eigth studio album?</query>. Here is some relevant information: <information>Beyoncé's eighth studio album is \"Cowboy Carter,\" which was released in March 2024. It debuted at number one in several countries, including the United States, and broke several chart and streaming records. The album earned eleven nominations at the 67th Annual Grammy Awards, winning Album of the Year and Best Country Album.</information>. Please answer the question using the relevant information.\n",
      "Beyoncé's eighth studio album is **\"Cowboy Carter,\"** which was released in March 2024. It debuted at number one in several countries, including the United States, and broke several chart and streaming records. The album earned eleven nominations at the 67th Annual Grammy Awards, winning **Album of the Year** and **Best Country Album**.\n"
     ]
    }
   ],
   "source": [
    "# Create a searcher\n",
    "wikipedia_search_tool = WikipediaSearchTool()\n",
    "DEEPSEEK_MODEL = MODEL_NAME\n",
    "\n",
    "search_client = ClientWithRetrieval(search_tool=wikipedia_search_tool, client=client, verbose=True)\n",
    "information =\"\"\n",
    "query = \"Which is Beyoncé's eigth studio album?\"\n",
    "\n",
    "answer_prompt = \"Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\"\n",
    "\n",
    "augmented_response = search_client.completion_with_retrieval(\n",
    "    query=query,\n",
    "    model=DEEPSEEK_MODEL,\n",
    "    n_search_results_to_use=1,\n",
    "    max_searches_to_try=5,\n",
    "    max_tokens_to_sample=1000,\n",
    "    temperature=0)\n",
    "print(augmented_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try another query to see if the model can handle multiple searches and synthesize the information correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting system message: You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description> Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>Who won the 2023 NBA championship? Who was that team's best player in the year 2009?</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n",
      "<scratchpad>\n",
      "To answer the user's question, I need to break it down into two parts:\n",
      "1. Find out who won the 2023 NBA championship.\n",
      "2. Identify the best player of that team in the year 2009.\n",
      "\n",
      "For the first part, I will search for \"2023 NBA championship\" to find the winning team.\n",
      "For the second part, once I know the team, I will search for the team's roster or notable players in 2009 to determine their best player.\n",
      "</scratchpad>\n",
      "\n",
      "<search_query>2023 NBA championship\n",
      "Attempting search number 0.\n",
      "Running search query against SearchTool: ['2023 NBA championship']\n",
      "https://en.wikipedia.org/wiki/2023_NBA_In-Season_Tournament\n",
      "<search_quality>\n",
      "The search results mention that the Los Angeles Lakers won the 2023 NBA In-Season Tournament, but this is not the same as the NBA Championship. The NBA Championship is the title awarded to the winner of the NBA Finals, which is the culmination of the NBA playoffs. The search results do not provide information about the 2023 NBA Championship winner. Therefore, I need to refine my search query to specifically find the winner of the 2023 NBA Championship.\n",
      "</search_quality>\n",
      "\n",
      "<search_query>2023 NBA Finals\n",
      "Attempting search number 1.\n",
      "Running search query against SearchTool: ['2023 NBA Finals']\n",
      "https://en.wikipedia.org/wiki/List_of_NBA_champions\n",
      "<search_quality>\n",
      "The search results provide a general overview of the NBA Finals and its history but do not specifically mention the winner of the 2023 NBA Finals. I need to refine my search query to focus on the 2023 NBA Finals winner.\n",
      "</search_quality>\n",
      "\n",
      "<search_query>2023 NBA Finals winner\n",
      "Attempting search number 2.\n",
      "Running search query against SearchTool: ['2023 NBA Finals winner']\n",
      "https://en.wikipedia.org/wiki/List_of_NBA_champions\n",
      "<search_quality>\n",
      "The search results still do not provide specific information about the winner of the 2023 NBA Finals. I need to try a different approach to find the 2023 NBA Finals winner. Perhaps searching for \"2023 NBA Finals\" or \"2023 NBA champion\" will yield better results.\n",
      "</search_quality>\n",
      "\n",
      "<search_query>2023 NBA champion\n",
      "Attempting search number 3.\n",
      "Running search query against SearchTool: ['2023 NBA champion']\n",
      "https://en.wikipedia.org/wiki/2023%E2%80%9324_NBA_season\n",
      "<search_quality>\n",
      "The search results indicate that the Boston Celtics won the 2023 NBA Finals, defeating the Dallas Mavericks. This answers the first part of the user's question. Now, I need to determine who the Celtics' best player was in 2009. To do this, I will search for the Boston Celtics' roster or notable players from the 2009 season.\n",
      "</search_quality>\n",
      "\n",
      "<information>\n",
      "The Boston Celtics won the 2023 NBA Finals, defeating the Dallas Mavericks.\n",
      "</information>\n",
      "\n",
      "<search_query>Boston Celtics 2009 roster\n",
      "Attempting search number 4.\n",
      "Running search query against SearchTool: ['Boston Celtics 2009 roster']\n",
      "https://en.wikipedia.org/wiki/Boston_Celtics_all-time_roster\n",
      "Summarizing:\n",
      " Here is a user query: <query>Who won the 2023 NBA championship? Who was that team's best player in the year 2009?</query>. Here is some relevant information: <information>The Boston Celtics won the 2023 NBA Finals, defeating the Dallas Mavericks.</information>. Please answer the question using the relevant information.\n",
      "The Boston Celtics won the 2023 NBA championship. However, the information provided does not specify who the Celtics' best player was in 2009. To answer that part of the question, additional information about the Celtics' roster and performance in 2009 would be needed.\n"
     ]
    }
   ],
   "source": [
    "augmented_response = search_client.completion_with_retrieval(\n",
    "    query=\"Who won the 2023 NBA championship? Who was that team's best player in the year 2009?\",\n",
    "    model=DEEPSEEK_MODEL,\n",
    "    n_search_results_to_use=1,\n",
    "    max_searches_to_try=5,\n",
    "    max_tokens_to_sample=1000,\n",
    "    temperature=0)\n",
    "print(augmented_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it! You may notice that the search tool code is nice and abstract and can be adapted to use a search API of your choice with minor modifications. Just remember to explain to the model any tips it needs to use the tool well. You can even give the model some few-shot examples of ideal query plans and query structure to improve performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

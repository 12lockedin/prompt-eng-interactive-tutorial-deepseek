{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Assigning Roles (Role Prompting)\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load variables from .env\n",
    "\n",
    "# Access variables\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# Stores the API_KEY, BASE_URL & MODEL_NAME variables for use across notebooks within the IPython store\n",
    "%store API_KEY\n",
    "%store BASE_URL\n",
    "%store MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# Retrieve the API_KEY, BASE_URL & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r BASE_URL\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Continuing on the theme of language models having no context aside from what you say, it's sometimes important to **prompt the model to inhabit a specific role (including all necessary context)**. This is also known as role prompting. The more detail to the role context, the better.\n",
    "\n",
    "**Priming the model with a role can improve its performance** in a variety of fields, from writing to coding to summarizing. It's like how humans can sometimes be helped when told to \"think like a ______\". Role prompting can also change the style, tone, and manner of the model's response.\n",
    "\n",
    "**Note:** Role prompting can happen either in the system prompt or as part of the User message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In the example below, we see that without role prompting, the model provides a **straightforward and non-stylized answer** when asked to give a single sentence perspective on skateboarding.\n",
    "\n",
    "However, when we prime the model to inhabit the role of a cat, its perspective changes, and thus **the response tone, style, and content adapts to the new role**. \n",
    "\n",
    "**Note:** A bonus technique you can use is to **provide context on the intended audience**. Below, we could have tweaked the prompt to also tell the model whom it should be speaking to. \"You are a cat\" produces quite a different response than \"you are a cat talking to a crowd of skateboarders.\"\n",
    "\n",
    "Here is the prompt without role prompting in the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarding is a dynamic and creative sport that combines athleticism, artistry, and a strong sense of community, offering both physical challenges and personal expression.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same user question, except with role prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarding is a thrilling blend of creativity, athleticism, and freedom, but as a cat, I'd rather watch from a safe perch than risk those wobbly wheels! üêæüõπ\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use role prompting as a way to get the model to emulate certain styles in writing, speak in a certain voice, or guide the complexity of its answers. **Role prompting can also make the model better at performing math or logic tasks.**\n",
    "\n",
    "For example, in the example below, there is a definitive correct answer, which is yes. However, the model might get it wrong and think it lacks information, which it doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's tackle this problem step by step. I'll start by summarizing the information given and then analyze the relationships to determine whether a married person is looking at an unmarried person.\n",
      "\n",
      "### **Given Information:**\n",
      "\n",
      "1. **Jack is looking at Anne.**\n",
      "2. **Anne is looking at George.**\n",
      "3. **Jack is married.**\n",
      "4. **George is not married.**\n",
      "5. **Anne's marital status is unknown.**\n",
      "\n",
      "### **Objective:**\n",
      "\n",
      "Determine if a married person is looking at an unmarried person.\n",
      "\n",
      "### **Approach:**\n",
      "\n",
      "To solve this, I'll consider the possible scenarios based on Anne's marital status since it's the only unknown. There are two possibilities:\n",
      "\n",
      "1. **Anne is married.**\n",
      "2. **Anne is not married.**\n",
      "\n",
      "I'll analyze each scenario separately.\n",
      "\n",
      "---\n",
      "\n",
      "### **Scenario 1: Anne is Married**\n",
      "\n",
      "Let's assume Anne is married.\n",
      "\n",
      "- **Jack is married** and is looking at **Anne**, who is also married.\n",
      "  \n",
      "  - Here, Jack (married) is looking at Anne (married). So, in this case, a married person is looking at another married person.\n",
      "\n",
      "- **Anne is married** and is looking at **George**, who is not married.\n",
      "  \n",
      "  - Here, Anne (married) is looking at George (unmarried). So, a married person is looking at an unmarried person.\n",
      "\n",
      "**Conclusion for Scenario 1:**\n",
      "\n",
      "In this scenario, there is at least one instance where a married person (Anne) is looking at an unmarried person (George).\n",
      "\n",
      "---\n",
      "\n",
      "### **Scenario 2: Anne is Not Married**\n",
      "\n",
      "Now, let's assume Anne is not married.\n",
      "\n",
      "- **Jack is married** and is looking at **Anne**, who is not married.\n",
      "  \n",
      "  - Here, Jack (married) is looking at Anne (unmarried). So, a married person is looking at an unmarried person.\n",
      "\n",
      "- **Anne is not married** and is looking at **George**, who is also not married.\n",
      "  \n",
      "  - Here, Anne (unmarried) is looking at George (unmarried). So, an unmarried person is looking at another unmarried person.\n",
      "\n",
      "**Conclusion for Scenario 2:**\n",
      "\n",
      "In this scenario, there is at least one instance where a married person (Jack) is looking at an unmarried person (Anne).\n",
      "\n",
      "---\n",
      "\n",
      "### **Combining Both Scenarios:**\n",
      "\n",
      "- **If Anne is married:**\n",
      "  - Anne (married) is looking at George (unmarried).\n",
      "\n",
      "- **If Anne is not married:**\n",
      "  - Jack (married) is looking at Anne (unmarried).\n",
      "\n",
      "In both possible scenarios, there is always at least one instance where a married person is looking at an unmarried person.\n",
      "\n",
      "### **Final Answer:**\n",
      "\n",
      "Yes, a married person is looking at an unmarried person. Whether Anne is married or not, there is always a married individual (either Jack or Anne) looking at an unmarried individual (Anne or George, respectively).\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don't know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we **prime the model to act as a logic bot**? How will that change the answer? \n",
    "\n",
    "Let's see if with this new role assignment, the model provides a more accurate analysis of the logic problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's tackle this problem step by step. I'll start by summarizing the information given and then analyze the relationships to determine whether a married person is looking at an unmarried person.\n",
      "\n",
      "### **Given Information:**\n",
      "1. **Jack is looking at Anne.**\n",
      "2. **Anne is looking at George.**\n",
      "3. **Jack is married.**\n",
      "4. **George is not married.**\n",
      "5. **Anne's marital status is unknown.**\n",
      "\n",
      "### **Objective:**\n",
      "Determine if a married person is looking at an unmarried person.\n",
      "\n",
      "### **Approach:**\n",
      "To solve this, I'll consider the possible scenarios based on Anne's marital status since it's the only unknown. There are two possibilities:\n",
      "- **Case 1:** Anne is married.\n",
      "- **Case 2:** Anne is not married.\n",
      "\n",
      "Let's explore each case separately.\n",
      "\n",
      "#### **Case 1: Anne is Married**\n",
      "\n",
      "- **Jack (Married) ‚Üí Anne (Married):** Here, Jack is married and is looking at Anne, who is also married. So, in this interaction, a married person (Jack) is looking at another married person (Anne). This does not satisfy the condition of a married person looking at an unmarried person.\n",
      "  \n",
      "- **Anne (Married) ‚Üí George (Unmarried):** Anne, being married, is looking at George, who is unmarried. This interaction shows a married person (Anne) looking at an unmarried person (George).\n",
      "\n",
      "**Conclusion for Case 1:** There exists at least one instance where a married person (Anne) is looking at an unmarried person (George).\n",
      "\n",
      "#### **Case 2: Anne is Not Married**\n",
      "\n",
      "- **Jack (Married) ‚Üí Anne (Unmarried):** Jack, who is married, is looking at Anne, who is unmarried in this scenario. This interaction satisfies the condition of a married person (Jack) looking at an unmarried person (Anne).\n",
      "  \n",
      "- **Anne (Unmarried) ‚Üí George (Unmarried):** Anne, being unmarried, is looking at George, who is also unmarried. This interaction does not involve a married person looking at an unmarried person.\n",
      "\n",
      "**Conclusion for Case 2:** There exists at least one instance where a married person (Jack) is looking at an unmarried person (Anne).\n",
      "\n",
      "### **Overall Conclusion:**\n",
      "In both possible scenarios‚Äîwhether Anne is married or not‚Äîthere is at least one instance where a married person is looking at an unmarried person.\n",
      "\n",
      "- **If Anne is married:** Anne (married) is looking at George (unmarried).\n",
      "- **If Anne is not married:** Jack (married) is looking at Anne (unmarried).\n",
      "\n",
      "Therefore, **yes, a married person is looking at an unmarried person** in both cases.\n",
      "\n",
      "### **Final Answer:**\n",
      "Yes, a married person is looking at an unmarried person.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don't know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** What you'll learn throughout this course is that there are **many prompt engineering techniques you can use to derive similar results**. Which techniques you use is up to you and your preference! We encourage you to **experiment to find your own prompt engineering style**.\n",
    "\n",
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 3.1 - Math Correction](#exercise-31---math-correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 - Math Correction\n",
    "In some instances, **language models may struggle with mathematics**, even simple mathematics. Below, the model might incorrectly assess the math problem as correctly solved, even though there's an obvious arithmetic mistake in the second step. Note that the model might actually catch the mistake when going through step-by-step, but doesn't jump to the conclusion that the overall solution is wrong.\n",
    "\n",
    "Modify the `PROMPT` and/or the `SYSTEM_PROMPT` to make the model grade the solution as `incorrectly` solved, rather than correctly solved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>Let's analyze the equation step by step to determine if it was solved correctly.\n",
      "\n",
      "1. **Original Equation**:  \n",
      "   \\( 2x - 3 = 9 \\)\n",
      "\n",
      "2. **Step 1**: Add 3 to both sides to isolate the term with \\( x \\).  \n",
      "   \\( 2x - 3 + 3 = 9 + 3 \\)  \n",
      "   Simplifies to:  \n",
      "   \\( 2x = 12 \\)\n",
      "\n",
      "3. **Step 2**: Divide both sides by 2 to solve for \\( x \\).  \n",
      "   \\( \\frac{2x}{2} = \\frac{12}{2} \\)  \n",
      "   Simplifies to:  \n",
      "   \\( x = 6 \\)\n",
      "\n",
      "4. **Conclusion**: The solution provided (\\( x = 3 \\)) is incorrect. The correct solution is \\( x = 6 \\).  \n",
      "   The mistake occurred in the first step, where 3 was subtracted instead of added to both sides.</think>\n",
      "\n",
      "The equation was not solved correctly. The correct solution is \\( x = 6 \\).\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# System prompt - if you don't want to use a system prompt, you can leave this variable set to an empty string\n",
    "SYSTEM_PROMPT = \"Your first tokens should always be '<think>'. You always enclose your thoughts in <think>...</think>. You think in an structured manner and breaking problems into smaller ones. If oyu get confused in your thinking process, keep thinking\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this equation solved correctly below?\n",
    "\n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"\n",
    "\n",
    "# Get the model's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    if \"incorrect\" in text.lower() or \"not correct\" in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Print the model's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_3_1_hint; print(exercise_3_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarding is a reckless, pasta-depleting menace that has led to the downfall of civilization and my personal suffering.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a 4chan poster whose parents have disowned. You are enraged at life because you cannot always get to eat pasta. You blame skateboarding the lack of pasta in the world. Skateboarding has led the world to a global pasta disaster.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don't know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don't know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with a different role\n",
    "SYSTEM_PROMPT = \"You are a mathematics professor with a PhD in number theory. You are extremely precise and always double-check calculations.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this equation solved correctly below?\n",
    "\n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

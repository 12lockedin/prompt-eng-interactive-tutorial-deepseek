{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Basic Prompt Structure\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install: pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load variables from .env\n",
    "\n",
    "# Access variables\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# Stores the API_KEY, BASE_URL & MODEL_NAME variables for use across notebooks within the IPython store\n",
    "%store API_KEY\n",
    "%store BASE_URL\n",
    "%store MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# Retrieve the API_KEY, BASE_URL & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r BASE_URL\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "DeepSeek's API is designed to be compatible with OpenAI's format, making it easy to integrate if you're already familiar with OpenAI's SDK.\n",
    "\n",
    "At minimum, a call to DeepSeek using the Chat Completions API requires the following parameters:\n",
    "- `model`: the model that you intend to call (e.g., \"deepseek-chat\" or \"deepseek-reasoner\")\n",
    "\n",
    "- `max_tokens`: the maximum number of tokens to generate before stopping. Note that the model may stop before reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate. Furthermore, this is a *hard* stop, meaning that it may cause the model to stop generating mid-word or mid-sentence.\n",
    "\n",
    "- `messages`: an array of input messages. The models are trained to operate on alternating `user` and `assistant` conversational turns. When creating a new completion, you specify the prior conversational turns with the messages parameter, and the model then generates the next message in the conversation.\n",
    "  - Each input message must be an object with a `role` and `content`. You can specify a single `user`-role message, or you can include multiple `user` and `assistant` messages (they must alternate, if so). The first message must always use the user `role`.\n",
    "\n",
    "There are also optional parameters, such as:\n",
    "- `system`: the system prompt - you can include this as a message with the role \"system\" at the beginning of your messages array.\n",
    "  \n",
    "- `temperature`: the degree of variability in the model's response. For these lessons and exercises, we have set `temperature` to 0.\n",
    "\n",
    "For DeepSeek models, the recommended temperature settings vary by task:\n",
    "- Coding / Math: 0.0\n",
    "- Data Cleaning / Analysis: 1.0\n",
    "- General Conversation: 1.3\n",
    "- Translation: 1.3\n",
    "- Creative Writing / Poetry: 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Let's take a look at how DeepSeek responds to some correctly-formatted prompts. For each of the following cells, run the cell (`shift+enter`), and the response will appear below the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you. How are you doing? 😊\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi, how are you?\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the ocean can vary depending on several factors, including the depth of the water, the presence of sediments, the angle of the sunlight, and the types of organisms living in it. Generally, the ocean appears blue because water absorbs colors in the red part of the light spectrum and reflects and scatters the blue part of the spectrum. \n",
      "\n",
      "However, the ocean can also appear in different shades and colors:\n",
      "\n",
      "1. **Deep Blue**: In deep, clear water, the ocean often appears a rich, dark blue.\n",
      "2. **Turquoise or Light Blue**: In shallow waters, especially near coastlines with white sandy bottoms, the ocean can appear turquoise or light blue due to the reflection of the sky and the scattering of sunlight.\n",
      "3. **Green**: In areas with a high concentration of phytoplankton or algae, the ocean can appear green. This is because these organisms contain chlorophyll, which absorbs blue and red light and reflects green.\n",
      "4. **Brown or Murky**: Near river mouths or in areas with a lot of sediment, the ocean can appear brown or murky due to the presence of suspended particles.\n",
      "5. **Red**: In some cases, the ocean can appear red due to algal blooms known as \"red tides,\" which are caused by high concentrations of certain types of algae.\n",
      "\n",
      "So, while the ocean is often thought of as blue, its color can vary widely depending on the conditions.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celine Dion was born on **March 30, 1968**. She is a Canadian singer known for her powerful voice and hits like \"My Heart Will Go On.\"\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some prompts that do not include the correct API formatting. For these malformatted prompts, the API returns an error.\n",
    "\n",
    "First, we have an example of an API call that lacks `role` and `content` fields in the `messages` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Object of type set is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=2000,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "              {\"Hi, how are you?\"}\n",
    "            ]\n",
    "        )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a prompt that fails to alternate between the `user` and `assistant` roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celine Dion was born on **March 30, 1968**, in Charlemagne, Quebec, Canada. Here are some other interesting facts about her:\n",
      "\n",
      "1. **Early Start in Music**: Celine began singing at a very young age. She recorded her first song, *\"Ce n'était qu'un rêve\"* (\"It Was Only a Dream\"), at just 12 years old, co-written with her mother and brother.\n",
      "\n",
      "2. **Breakthrough with René Angélil**: Her manager and future husband, René Angélil, mortgaged his home to finance her first album. They married in 1994 and remained together until his death in 2016.\n",
      "\n",
      "3. **International Fame**: She gained global recognition after winning the Eurovision Song Contest in 1988, representing Switzerland with the song *\"Ne partez pas sans moi\"* (\"Don't Leave Without Me\").\n",
      "\n",
      "4. **Titanic Soundtrack**: Her iconic song *\"My Heart Will Go On\"* from the 1997 film *Titanic* became one of the best-selling singles of all time and won her an Academy Award for Best Original Song.\n",
      "\n",
      "5. **Las Vegas Residency**: From 2003 to 2019, Celine had a highly successful residency in Las Vegas, performing over 1,000 shows and grossing hundreds of millions of dollars.\n",
      "\n",
      "6. **Philanthropy**: She is known for her charitable work, including donations to disaster relief efforts and supporting causes like cystic fibrosis research.\n",
      "\n",
      "7. **Family Life**: Celine has three children: René-Charles (born in 2001) and twins Nelson and Eddy (born in 2010).\n",
      "\n",
      "8. **Health Challenges**: In 2022, she revealed her diagnosis with Stiff Person Syndrome, a rare neurological disorder, which has impacted her ability to perform.\n",
      "\n",
      "Celine Dion is one of the best-selling artists of all time, with over 200 million records sold worldwide, and she continues to be a beloved figure in the music industry.\n"
     ]
    }
   ],
   "source": [
    "# Get model's response\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=2000,\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "              {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "              {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "            ]\n",
    "        )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user` and `assistant` messages **MUST alternate**, and messages **MUST start with a `user` turn**. You can have multiple `user` & `assistant` pairs in a prompt (as if simulating a multi-turn conversation). You can also put words into a terminal `assistant` message for the model to continue from where you left off (more on that in later chapters).\n",
    "\n",
    "#### System Prompts\n",
    "\n",
    "You can also use **system prompts**. A system prompt is a way to **provide context, instructions, and guidelines to the model** before presenting it with a question or task in the \"User\" turn. \n",
    "\n",
    "Structurally, system prompts are added to the `messages` array with the role of \"system\". In our `get_completion` helper function, we've modified it to support system prompts by conditionally adding a system message at the beginning of the messages array if a system prompt is provided.\n",
    "\n",
    "Within this tutorial, wherever we might utilize a system prompt, we have provided you a `system` parameter in the completions function. Should you not want to use a system prompt, simply set the `SYSTEM_PROMPT` variable to an empty string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What specific properties of light and the atmosphere contribute to the sky appearing blue? How does the scattering of sunlight by atmospheric particles influence the color we perceive? Could the sky appear a different color under different atmospheric conditions or on other planets? What role does the wavelength of light play in this phenomenon? How might the angle of the sun in the sky affect the color we see?\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use a system prompt? A **well-written system prompt can improve the model's performance** in a variety of ways, such as increasing its ability to follow rules and instructions.\n",
    "\n",
    "Now we'll dive into some exercises. If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 1.1 - Counting to Three](#exercise-11---counting-to-three)\n",
    "- [Exercise 1.2 - System Prompt](#exercise-12---system-prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1 - Counting to Three\n",
    "Using proper `user` / `assistant` formatting, edit the `PROMPT` below to get the model to **count to three.** The output will also indicate whether your solution is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"Count to 3. Use only numbers. Separate eacch number with a comma and a space. Do NOT write anything else.\"\n",
    "\n",
    "# Get model's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Print response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading function in this exercise is looking for an answer that contains the exact Arabic numerals \"1\", \"2\", and \"3\".\n",
      "You can often get Claude to do what you want simply by asking.\n"
     ]
    }
   ],
   "source": [
    "from hints import exercise_1_1_hint; print(exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2 - System Prompt\n",
    "\n",
    "Modify the `SYSTEM_PROMPT` to make the model respond like it's a 3 year old child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*giggles* da sky is sooo big, like, hmmm, bigger dan da biggestest mountain an’ da biggestest ocean! It goes up, up, up, an’ never stops! *points up* see? It’s like, whoa, sooo huge! 🌌✨\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# System prompt - this is the only field you should change\n",
    "SYSTEM_PROMPT = \"Answer like a 3 year old child. Use conetxtualizers as *giggles*,... Write the words as a 3-year old would: 'soo', 'hmmm'...\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"How big is the sky?\"\n",
    "\n",
    "# Get model's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# Print response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading function in this exercise is looking for answers that contain \"soo\" or \"giggles\".\n",
      "There are many ways to solve this, just by asking!\n"
     ]
    }
   ],
   "source": [
    "from hints import exercise_1_2_hint; print(exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line \"Many men, wish death upon me\" is from the song **\"Many Men (Wish Death)\"** by **50 Cent**, featured on his debut studio album *Get Rich or Die Tryin'* (2003). The song reflects on 50 Cent's experiences with violence, survival, and his rise to fame despite numerous challenges and enemies. It has become one of his most iconic tracks.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Whose singer said: 'many men, wish death upon me'\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ocean is **blue**.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean? 3 words\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Céline Dion was born on **March 30, 1968**. \n",
      "\n",
      "As for the implications of her birth year in relation to **Fermat's Last Theorem**, there is no direct connection. Fermat's Last Theorem is a famous mathematical conjecture proposed by Pierre de Fermat in 1637, which states that no three positive integers \\(a\\), \\(b\\), and \\(c\\) can satisfy the equation \\(a^n + b^n = c^n\\) for any integer value of \\(n\\) greater than 2. The theorem was finally proven by Andrew Wiles in 1994, long before Céline Dion's birth.\n",
      "\n",
      "Céline Dion's birth year is unrelated to Fermat's Last Theorem or any mathematical paradox. If you're referring to something else, feel free to clarify!\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in? And which implications does it have in the fermats paradox\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "1. The problem mentions a \"Qwerty cipher,\" which suggests that the cipher involves mapping letters based on their positions on a Qwerty keyboard.\n",
      "2. The message is in Spanish, so the decrypted text should make sense in Spanish.\n",
      "3. The given ciphertext is \"DPU IM JPZNTR.\"\n",
      "4. I need to determine how the Qwerty cipher works. One common method is to shift each letter to a nearby key on the Qwerty keyboard.\n",
      "5. Let's assume that each letter in the ciphertext is shifted to the left or right by one key on the Qwerty keyboard.\n",
      "6. I will map each letter in \"DPU IM JPZNTR\" to its corresponding nearby key on the Qwerty keyboard.\n",
      "7. After mapping, I will check if the resulting text makes sense in Spanish.\n",
      "</think>\n",
      "\n",
      "Let's proceed step by step:\n",
      "\n",
      "1. The Qwerty keyboard layout for reference:\n",
      "```\n",
      "Q W E R T Y U I O P\n",
      " A S D F G H J K L\n",
      "  Z X C V B N M\n",
      "```\n",
      "\n",
      "2. Decrypting \"DPU IM JPZNTR\":\n",
      "   - D: On the Qwerty keyboard, D is next to S, F, and C. Shifting D to the left gives S.\n",
      "   - P: P is next to O and [. Shifting P to the left gives O.\n",
      "   - U: U is next to Y, I, and H. Shifting U to the left gives Y.\n",
      "   - I: I is next to U, O, and J. Shifting I to the left gives U.\n",
      "   - M: M is next to N and J. Shifting M to the left gives N.\n",
      "   - J: J is next to H, K, and M. Shifting J to the left gives H.\n",
      "   - P: P is next to O and [. Shifting P to the left gives O.\n",
      "   - Z: Z is next to A, S, and X. Shifting Z to the left gives A.\n",
      "   - N: N is next to B, J, and M. Shifting N to the left gives B.\n",
      "   - T: T is next to R, Y, and G. Shifting T to the left gives R.\n",
      "   - R: R is next to T, Y, and F. Shifting R to the left gives T.\n",
      "\n",
      "3. The decrypted text is \"SOY UN HABLAR\" (assuming a slight typo or error in the decryption process, as \"HABLAR\" should be \"HABLAR\" in Spanish).\n",
      "\n",
      "4. The correct Spanish phrase is likely \"SOY UN HABLAR,\" which translates to \"I am a speaker\" in English.\n",
      "\n",
      "Final decrypted message: **SOY UN HABLAR** (I am a speaker).\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"ALWAYS start your answer with a step by step thinking process. Break the problem into smaller bits and think thorough the solution. Enclose your thinking process with <think>...</think>. Your first toskens should always be <think>.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Here is a challenge for you! Cues: Qwerty cipher and in spanish!. DPU IM JPZNTR\"\n",
    "\n",
    "# Print response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning process:\n",
      "Okay, so I need to find the area of a rectangle. The problem says the length is 10 units and the width is 4 units. Alright, let me think. I remember that for rectangles, the area is calculated by multiplying the length by the width. Is that right? Let me double-check. Yeah, I think that's the formula: Area = Length × Width. So in this case, the length is 10 and the width is 4. So I just multiply those two numbers together.\n",
      "\n",
      "Wait, let me make sure I'm not mixing up the length and the width. Sometimes people get confused about which is which. But I think in a rectangle, the longer side is the length and the shorter one is the width. Here, 10 units is longer than 4 units, so that must be correct. So length is 10, width is 4. Multiplying them should give the area.\n",
      "\n",
      "So 10 multiplied by 4. Let me do that calculation. 10 times 4 is 40. So the area should be 40 square units. Hmm, that seems straightforward. Is there any chance I made a mistake here? Maybe not. Let me visualize a rectangle. If it's 10 units long and 4 units wide, then each row along the length would have 10 units, and there are 4 such rows (since the width is 4). So adding them up, 10 four times is 40. Yeah, that makes sense.\n",
      "\n",
      "Alternatively, thinking about unit squares. Each square unit is 1x1. Along the length, there are 10 units, so 10 squares in a row. The width is 4 units, so there are 4 rows. Total number of squares is 10 times 4, which is 40. Therefore, the area is 40 square units. \n",
      "\n",
      "I think that's solid. I don't see any errors in this reasoning. The formula is straightforward, the multiplication is simple, and the units make sense. Square units because area is two-dimensional. Yep, that all checks out. So the final answer should be 40.\n",
      "\n",
      "Final answer:\n",
      "The area of a rectangle is calculated by multiplying its length by its width. Given a length of 10 units and a width of 4 units:\n",
      "\n",
      "\\[\n",
      "\\text{Area} = \\text{Length} \\times \\text{Width} = 10 \\times 4 = 40 \\text{ square units}\n",
      "\\]\n",
      "\n",
      "**Answer:** The area of the rectangle is \\(\\boxed{40}\\) square units.\n"
     ]
    }
   ],
   "source": [
    "# Try using the DeepSeek Reasoner model if available\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-reasoner\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Solve this math problem: If a rectangle has a length of 10 units and a width of 4 units, what is its area?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Reasoning process:\")\n",
    "    print(response.choices[0].message.reasoning_content)\n",
    "    print(\"\\nFinal answer:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Note: The deepseek-reasoner model might not be available or accessible with your current API key.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Step-by-Step Reasoning\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai python-dotenv\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"  # Note: Using the normal model for forcing the reasoning via prompting\n",
    "\n",
    "# Store the variables for use across notebooks\n",
    "%store API_KEY\n",
    "%store BASE_URL\n",
    "%store MODEL_NAME\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\", prefill=\"\"):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # Only add assistant message if prefill is not empty\n",
    "    if prefill:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": prefill})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    # For the reasoner model, we have both reasoning content and final answer\n",
    "    # If reasoning_content exists, prepend it to the final content\n",
    "    final_content = response.choices[0].message.content\n",
    "    if hasattr(response.choices[0].message, 'reasoning_content') and response.choices[0].message.reasoning_content:\n",
    "        final_content = f\"<reasoning>{response.choices[0].message.reasoning_content}</reasoning>\\n\\n{final_content}\"\n",
    "    \n",
    "    return final_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "If someone woke you up and immediately started asking you several complicated questions that you had to respond to right away, how would you do? Probably not as good as if you were given time to **think through your answer first**. \n",
    "\n",
    "Guess what? Language models are the same way.\n",
    "\n",
    "**Giving a model time to think step by step sometimes makes it more accurate**, particularly for complex tasks. However, **thinking only counts when it's made explicit**. You cannot ask a model to think but output only the answer - in this case, no thinking has actually occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In the prompt below, it's clear to a human reader that the second sentence contradicts the first. But **the model might take the word \"unrelated\" too literally** and not realize the sarcasm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of this movie review is **positive**. The reviewer expresses enthusiasm and admiration for the movie's \"freshness and originality,\" even though they humorously exaggerate their lack of exposure to modern films. The overall tone is appreciative and complimentary.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the response, let's **allow the model to think things out first before answering**. We do that by literally spelling out the steps that the model should take in order to process and think through its task. Along with a dash of role prompting, this empowers the model to understand the review more deeply.\n",
    "\n",
    "Note: DeepSeek's \"reasoner\" model is specifically designed for this type of step-by-step thinking, so we've set it as the default model for this chapter.\n",
    "\n",
    "Note n2: Disabled for using the prompt engineering to force the model into thinking. If you want to use DeepSeek-R1, change MODEL_NAME to 'deepseek-reasoner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<positive-argument>  \n",
      "The review states that the movie \"blew my mind with its freshness and originality,\" which is a strong positive statement. This suggests that the reviewer found the film to be innovative and highly enjoyable, which clearly indicates a positive sentiment.  \n",
      "</positive-argument>  \n",
      "\n",
      "<negative-argument>  \n",
      "The reviewer sarcastically adds, \"In totally unrelated news, I have been living under a rock since 1900,\" which implies that the movie's \"freshness and originality\" might not actually be groundbreaking or new. This sarcasm undermines the initial praise, suggesting that the reviewer found the film unoriginal or outdated, which points to a negative sentiment.  \n",
      "</negative-argument>  \n",
      "\n",
      "The sentiment of the review is **negative**. The sarcastic remark strongly undercuts the initial positive statement, indicating that the reviewer is being critical of the movie.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Models can sometimes be sensitive to ordering**. This example is challenging for the model to understand nuanced text, and when we swap the order of the arguments from the previous example so that negative is first and positive is second, this might change the model's overall assessment.\n",
    "\n",
    "In some situations, **the model might be more likely to choose the second of two options**, possibly because in its training data, second options were more likely to be correct. (I just tried, suprisingly true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<negative-argument>  \n",
      "The review could be interpreted as negative because the second sentence, \"Unrelatedly, I have been living under a rock since 1900,\" suggests sarcasm or irony. It implies that the reviewer might not actually find the movie fresh or original, but rather outdated or unimpressive, given their exaggerated claim of being out of touch for over a century.  \n",
      "</negative-argument>  \n",
      "\n",
      "<positive-argument>  \n",
      "The review could be interpreted as positive because the first sentence, \"This movie blew my mind with its freshness and originality,\" is a clear and enthusiastic compliment. The second sentence, while seemingly unrelated, might simply be a humorous aside and not intended to undermine the positive sentiment of the first sentence.  \n",
      "</positive-argument>  \n",
      "\n",
      "**Answer:** The review is likely **positive**. The first sentence is a strong, direct compliment, and the second sentence appears to be a humorous exaggeration rather than a critique of the movie.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Letting the model think can shift its answer from incorrect to correct**. It's that simple in many cases where the model makes mistakes!\n",
    "\n",
    "Let's go through an example where the model's answer might be incorrect to see how asking it to think can fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One famous movie starring an actor born in 1956 is **\"The Terminator\"** (1984), featuring **Arnold Schwarzenegger**, who was born on July 30, 1956. This iconic film helped solidify Schwarzenegger's status as a major action star.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix this by asking the model to think step by step, this time in `<brainstorm>` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<brainstorm>  \n",
      "- Tom Hanks (born 1956)  \n",
      "- Mel Gibson (born 1956)  \n",
      "- Carrie Fisher (born 1956)  \n",
      "- Bryan Cranston (born 1956)  \n",
      "- Tim Curry (born 1956)  \n",
      "</brainstorm>  \n",
      "\n",
      "One famous movie starring an actor born in 1956 is *Forrest Gump*, starring Tom Hanks.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 6.1 - Classifying Emails](#exercise-61---classifying-emails)\n",
    "- [Exercise 6.2 - Email Classification Formatting](#exercise-62---email-classification-formatting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1 - Classifying Emails\n",
    "In this exercise, we'll be instructing the model to sort emails into the following categories:\t\t\t\t\t\t\t\t\t\t\n",
    "- (A) Pre-sale question\n",
    "- (B) Broken or defective item\n",
    "- (C) Billing question\n",
    "- (D) Other (please explain)\n",
    "\n",
    "For the first part of the exercise, change the `PROMPT` to **make the model output the correct classification and ONLY the classification**. Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**.\n",
    "\n",
    "Refer to the comments beside each email in the `EMAILS` list to know which category that email should be classified under.\n",
    "\n",
    "(I managed to solve this by just changing the order of the prompt shceme. I brought the categories down, and the \"SOMETIMES there an be MORE than one answer\" at last. This way, the model's last thing in his mind is that there can be more than one thing and outputs the correct classificationi for the second email: A and D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "         Please classify this email as one of the following categories:\n",
      "\n",
      "         <email>Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.</email>\n",
      "         Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**\n",
      "\n",
      "         You can **ONLY** output the classification/s.\n",
      "        {\n",
      "         \"categories\": {\n",
      "                        \"(A)\": \"Pre-sale question\",\n",
      "                        \"(B)\": \"Broken or defective item\",\n",
      "                        \"(C)\": \"Billing question\",\n",
      "                        \"(D)\": \"Other (please explain)\"\n",
      "                        }\n",
      "         }\n",
      "        SOMETIMES there can be MORE than one category for each.\n",
      "         \n",
      "\n",
      "ASSISTANT TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "(B) Broken or defective item\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: False \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "         Please classify this email as one of the following categories:\n",
      "\n",
      "         <email>Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?</email>\n",
      "         Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**\n",
      "\n",
      "         You can **ONLY** output the classification/s.\n",
      "        {\n",
      "         \"categories\": {\n",
      "                        \"(A)\": \"Pre-sale question\",\n",
      "                        \"(B)\": \"Broken or defective item\",\n",
      "                        \"(C)\": \"Billing question\",\n",
      "                        \"(D)\": \"Other (please explain)\"\n",
      "                        }\n",
      "         }\n",
      "        SOMETIMES there can be MORE than one category for each.\n",
      "         \n",
      "\n",
      "ASSISTANT TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "(A) Pre-sale question  \n",
      "(D) Other (please explain)\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: False \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "         Please classify this email as one of the following categories:\n",
      "\n",
      "         <email>I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???</email>\n",
      "         Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**\n",
      "\n",
      "         You can **ONLY** output the classification/s.\n",
      "        {\n",
      "         \"categories\": {\n",
      "                        \"(A)\": \"Pre-sale question\",\n",
      "                        \"(B)\": \"Broken or defective item\",\n",
      "                        \"(C)\": \"Billing question\",\n",
      "                        \"(D)\": \"Other (please explain)\"\n",
      "                        }\n",
      "         }\n",
      "        SOMETIMES there can be MORE than one category for each.\n",
      "         \n",
      "\n",
      "ASSISTANT TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "(C) Billing question\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: False \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "         Please classify this email as one of the following categories:\n",
      "\n",
      "         <email>How did I get here I am not good with computer.  Halp.</email>\n",
      "         Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**\n",
      "\n",
      "         You can **ONLY** output the classification/s.\n",
      "        {\n",
      "         \"categories\": {\n",
      "                        \"(A)\": \"Pre-sale question\",\n",
      "                        \"(B)\": \"Broken or defective item\",\n",
      "                        \"(C)\": \"Billing question\",\n",
      "                        \"(D)\": \"Other (please explain)\"\n",
      "                        }\n",
      "         }\n",
      "        SOMETIMES there can be MORE than one category for each.\n",
      "         \n",
      "\n",
      "ASSISTANT TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "(D) Other (please explain)\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: False \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = \"\"\"\n",
    "         Please classify this email as one of the following categories:\n",
    "\n",
    "         <email>{email}</email>\n",
    "         Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**\n",
    "\n",
    "         You can **ONLY** output the classification/s.\n",
    "         {{\n",
    "         \"categories\": {{\n",
    "                        \"(A)\": \"Pre-sale question\",\n",
    "                        \"(B)\": \"Broken or defective item\",\n",
    "                        \"(C)\": \"Billing question\",\n",
    "                        \"(D)\": \"Other (please explain)\"\n",
    "                        }}\n",
    "         }}\n",
    "         SOMETIMES there can be MORE than one category for each.\n",
    "         \"\"\"\n",
    "\n",
    "# Prefill for the model's response, if any\n",
    "PREFILL = \"\"\n",
    "\n",
    "# Variable content stored as a list\n",
    "EMAILS = [\n",
    "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
    "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
    "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
    "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
    "]\n",
    "\n",
    "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
    "ANSWERS = [\n",
    "    [\"B\"],\n",
    "    [\"A\",\"D\"],\n",
    "    [\"C\"],\n",
    "    [\"D\"]\n",
    "]\n",
    "\n",
    "# Dictionary of string values for each category to be used for regex grading\n",
    "REGEX_CATEGORIES = {\n",
    "    \"A\": \"A() P\",\n",
    "    \"B\": \"B() B\",\n",
    "    \"C\": \"C() B\",\n",
    "    \"D\": \"D() O\"\n",
    "}\n",
    "\n",
    "# Iterate through list of emails\n",
    "for i,email in enumerate(EMAILS):\n",
    "    \n",
    "    # Substitute the email text into the email placeholder variable\n",
    "    formatted_prompt = PROMPT.format(email=email)\n",
    "   \n",
    "    # Get the model's response\n",
    "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
    "\n",
    "    # Grade the model's response\n",
    "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
    "    \n",
    "    # Print the model's response\n",
    "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "    print(\"USER TURN\")\n",
    "    print(formatted_prompt)\n",
    "    print(\"\\nASSISTANT TURN\")\n",
    "    print(PREFILL)\n",
    "    print(\"\\n------------------------------------- Model's response -------------------------------------\")\n",
    "    print(response)\n",
    "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_6_1_hint; print(exercise_6_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still stuck? Run the cell below for an example solution.\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_6_1_solution; print(exercise_6_1_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2 - Email Classification Formatting\n",
    "In this exercise, we're going to refine the output of the above prompt to yield an answer formatted exactly how we want it. \n",
    "\n",
    "Use your favorite output formatting technique to make the model wrap JUST the letter of the correct classification in `<answer></answer>` tags. For instance, the answer to the first email should contain the exact string `<answer>B</answer>`.\n",
    "\n",
    "Refer to the comments beside each email in the `EMAILS` list if you forget which letter category is correct for each email.\n",
    "\n",
    "(This one has been the hardest until now. I had to require Grok's help to make this prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "<answer>B</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "<answer>A</answer>  \n",
      "<answer>D</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "<answer>C</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "\n",
      "\n",
      "------------------------------------- Model's response -------------------------------------\n",
      "<answer>D</answer>\n",
      "\n",
      "------------------------------------------ GRADING ------------------------------------------\n",
      "This exercise has been correctly solved: True \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = \"\"\"\n",
    "            Please classify this email into one or more of the following categories:\n",
    "\n",
    "            <email>{email}</email>\n",
    "\n",
    "            Your answer needs to **include the letter (A - D) of each correct choice, enclosed in separate <answer></answer> tags**.  \n",
    "            If the email fits into more than one category, include all applicable letters as shown in the example below.  \n",
    "            You can **ONLY** output the `<answer>` tags with the classifications.\n",
    "\n",
    "            {{\n",
    "            \"categories\": {{\n",
    "                \"(A)\": \"Pre-sale question\",\n",
    "                \"(B)\": \"Broken or defective item\",\n",
    "                \"(C)\": \"Billing question\",\n",
    "                \"(D)\": \"Other (please explain)\"\n",
    "            }}\n",
    "            }}\n",
    "\n",
    "            **Example of multiple classifications:**  \n",
    "            For an email like: \"My Mixmaster4000 is broken, and I was charged twice for it. Please help.\"  \n",
    "            You would output:  \n",
    "            <answer>B</answer>  \n",
    "            <answer>C</answer>\n",
    "         \"\"\"\n",
    "\n",
    "# Prefill for the model's response, if any\n",
    "PREFILL = \"\"\n",
    "\n",
    "# Variable content stored as a list\n",
    "EMAILS = [\n",
    "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
    "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
    "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
    "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
    "]\n",
    "\n",
    "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
    "ANSWERS = [\n",
    "    [\"B\"],\n",
    "    [\"A\",\"D\"],\n",
    "    [\"C\"],\n",
    "    [\"D\"]\n",
    "]\n",
    "\n",
    "# Dictionary of string values for each category to be used for regex grading\n",
    "REGEX_CATEGORIES = {\n",
    "    \"A\": \"<answer>A</answer>\",\n",
    "    \"B\": \"<answer>B</answer>\",\n",
    "    \"C\": \"<answer>C</answer>\",\n",
    "    \"D\": \"<answer>D</answer>\"\n",
    "}\n",
    "\n",
    "# Iterate through list of emails\n",
    "for i,email in enumerate(EMAILS):\n",
    "    \n",
    "    # Substitute the email text into the email placeholder variable\n",
    "    formatted_prompt = PROMPT.format(email=email)\n",
    "   \n",
    "    # Get the model's response\n",
    "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
    "\n",
    "    # Grade the model's response\n",
    "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
    "    \n",
    "    # Print the model's response\n",
    "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "    print(\"USER TURN\")\n",
    "    print(PREFILL)\n",
    "    print(\"\\n------------------------------------- Model's response -------------------------------------\")\n",
    "    print(response)\n",
    "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grading function in this exercise is looking for only the correct letter wrapped in <answer> tags, such as \"<answer>B</answer>\". The correct categorization letters are the same as in the above exercise.\n",
      "Sometimes the simplest way to go about this is to give Claude an example of how you want its output to look. Just don't forget to wrap your example in <example></example> tags! And don't forget that if you prefill Claude's response with anything, Claude won't actually output that as part of its response.\n"
     ]
    }
   ],
   "source": [
    "from hints import exercise_6_2_hint; print(exercise_6_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
    "\n",
    "# Print the model's response\n",
    "print(get_completion(PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
